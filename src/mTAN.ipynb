{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mTAN - Imputation Model\n",
    "\n",
    "Here we will test out the mTAN imputation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "path = '../../toy_dataset/'\n",
    "sys.path.append(path)\n",
    "\n",
    "from data_utils import ToyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = '/home2/joshua.wendland/Documents/sepsis/toy_dataset/synthetic_ts_1/synthetic_ts_test_data_eav.csv.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import, Import, Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "from random import SystemRandom\n",
    "import models\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=128, classif=False, dataset='toy', dec='mtan_rnn', dec_num_heads=1, dec_rnn=True, dropout=0.0, embed_time=128, enc='mtan_rnn', enc_num_heads=1, enc_rnn=True, fname=None, gen_hidden=50, k_iwae=5, kl=True, latent_dim=1, learn_emb=True, length=20, lr=0.0001, n=1000, niters=5, norm=True, num_ref_points=20, only_periodic=None, quantization=0.016, rec_hidden=32, sample_tp=1.0, save=1, seed=0, std=0.01)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--niters', type=int, default=2000, help='Number of epochs')\n",
    "parser.add_argument('--lr', type=float, default=0.01)\n",
    "parser.add_argument('--std', type=float, default=0.01)\n",
    "parser.add_argument('--latent-dim', type=int, default=32)\n",
    "parser.add_argument('--rec-hidden', type=int, default=32)\n",
    "parser.add_argument('--gen-hidden', type=int, default=50)\n",
    "parser.add_argument('--embed-time', type=int, default=128)\n",
    "parser.add_argument('--k-iwae', type=int, default=10)\n",
    "parser.add_argument('--save', type=int, default=1)\n",
    "parser.add_argument('--enc', type=str, default='mtan_rnn')\n",
    "parser.add_argument('--dec', type=str, default='mtan_rnn')\n",
    "parser.add_argument('--fname', type=str, default=None)\n",
    "parser.add_argument('--seed', type=int, default=0)\n",
    "parser.add_argument('--n', type=int, default=8000)\n",
    "parser.add_argument('--batch-size', type=int, default=50)\n",
    "parser.add_argument('--quantization', type=float, default=0.016,\n",
    "                    help=\"Quantization on the physionet dataset.\")\n",
    "parser.add_argument('--classif', action='store_true',\n",
    "                    help=\"Include binary classification loss\")\n",
    "parser.add_argument('--norm', action='store_true')\n",
    "parser.add_argument('--kl', action='store_true')\n",
    "parser.add_argument('--learn-emb', action='store_true')\n",
    "parser.add_argument('--enc-num-heads', type=int, default=1)\n",
    "parser.add_argument('--dec-num-heads', type=int, default=1)\n",
    "parser.add_argument('--length', type=int, default=20)\n",
    "parser.add_argument('--num-ref-points', type=int, default=128)\n",
    "parser.add_argument('--dataset', type=str, default='toy')\n",
    "parser.add_argument('--enc-rnn', action='store_false')\n",
    "parser.add_argument('--dec-rnn', action='store_false')\n",
    "parser.add_argument('--sample-tp', type=float, default=1.0)\n",
    "parser.add_argument('--only-periodic', type=str, default=None)\n",
    "parser.add_argument('--dropout', type=float, default=0.0)\n",
    "\n",
    "\n",
    "new_args = ['--niters', '5', '--lr', '0.0001', '--batch-size', '2', '--rec-hidden', '32', '--latent-dim', '1', '--length', '20', '--enc', 'mtan_rnn', '--dec', 'mtan_rnn', '--n', '1000',  '--gen-hidden', '50', '--save', '1', '--k-iwae', '5', '--std', '0.01', '--norm', '--learn-emb', '--kl', '--seed', '0', '--num-ref-points', '20', '--dataset', 'toy_josh'] # interpolation task on josh dataset\n",
    "new_args = ['--niters', '5', '--lr', '0.0001', '--batch-size', '128', '--rec-hidden', '32', '--latent-dim', '1', '--length', '20', '--enc', 'mtan_rnn', '--dec', 'mtan_rnn', '--n', '1000',  '--gen-hidden', '50', '--save', '1', '--k-iwae', '5', '--std', '0.01', '--norm', '--learn-emb', '--kl', '--seed', '0', '--num-ref-points', '20', '--dataset', 'toy']  # original Interpolation task on toy dataset\n",
    "args = parser.parse_args(new_args)\n",
    "print((args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=128, classif=False, dataset='toy', dec='mtan_rnn', dec_num_heads=1, dec_rnn=True, dropout=0.0, embed_time=128, enc='mtan_rnn', enc_num_heads=1, enc_rnn=True, fname=None, gen_hidden=50, k_iwae=5, kl=True, latent_dim=1, learn_emb=True, length=20, lr=0.0001, n=1000, niters=5, norm=True, num_ref_points=20, only_periodic=None, quantization=0.016, rec_hidden=32, sample_tp=1.0, save=1, seed=0, std=0.01) 69339\n",
      "(1000, 20) (1000, 20) (1000, 100)\n",
      "(1000, 20, 3)\n",
      "[[ 0.8516054   1.          0.09      ]\n",
      " [ 0.95830714  1.          0.2       ]\n",
      " [ 1.33468433  1.          0.25      ]\n",
      " [ 1.95121209  1.          0.37      ]\n",
      " [ 1.88823672  1.          0.39      ]\n",
      " [ 1.18921462  1.          0.46      ]\n",
      " [ 1.03273212  1.          0.47      ]\n",
      " [ 0.70050108  1.          0.49      ]\n",
      " [ 0.26575831  1.          0.64      ]\n",
      " [ 0.42114019  1.          0.69      ]\n",
      " [ 0.33637057  1.          0.72      ]\n",
      " [ 0.08979964  1.          0.77      ]\n",
      " [ 0.01292361  1.          0.79      ]\n",
      " [-0.01584657  1.          0.8       ]\n",
      " [-0.03790797  1.          0.81      ]\n",
      " [-0.05342294  1.          0.82      ]\n",
      " [-0.04604355  1.          0.87      ]\n",
      " [-0.03038688  1.          0.88      ]\n",
      " [-0.03038688  1.          0.88      ]\n",
      " [ 0.27021355  1.          0.99      ]]\n",
      "(800, 20, 3) (200, 20, 3)\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds\n",
    "experiment_id = int(SystemRandom().random() * 100000)\n",
    "print(args, experiment_id)\n",
    "seed = args.seed\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "# Set the device to run calculation on\n",
    "device = torch.device(\n",
    "    'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# consider the correct dataset\n",
    "if args.dataset == 'toy':\n",
    "    data_obj = utils.kernel_smoother_data_gen(args, alpha=100., seed=0)\n",
    "elif args.dataset == 'toy_josh':\n",
    "    data_obj = utils.get_toy_data_josh(args, path=path_dataset)\n",
    "\n",
    "train_loader = data_obj[\"train_dataloader\"]\n",
    "test_loader = data_obj[\"test_dataloader\"]\n",
    "dim = data_obj[\"input_dim\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 20, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(train_loader))\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder:  mtan_rnn \n",
      "Decoder:  mtan_rnn\n"
     ]
    }
   ],
   "source": [
    "if args.enc == 'enc_rnn3':\n",
    "    rec = models.enc_rnn3(\n",
    "        dim, torch.linspace(0, 1., args.num_ref_points), args.latent_dim, \n",
    "        args.rec_hidden, 128, learn_emb=args.learn_emb).to(device)\n",
    "elif args.enc == 'mtan_rnn':\n",
    "    rec = models.enc_mtan_rnn(\n",
    "        dim, torch.linspace(0, 1., args.num_ref_points), args.latent_dim, args.rec_hidden, \n",
    "        embed_time=128, learn_emb=args.learn_emb, num_heads=args.enc_num_heads).to(device)\n",
    "\n",
    "    \n",
    "if args.dec == 'rnn3':\n",
    "    dec = models.dec_rnn3(\n",
    "        dim, torch.linspace(0, 1., args.num_ref_points), args.latent_dim, \n",
    "        args.gen_hidden, 128, learn_emb=args.learn_emb).to(device)\n",
    "elif args.dec == 'mtan_rnn':\n",
    "    dec = models.dec_mtan_rnn(\n",
    "        dim, torch.linspace(0, 1., args.num_ref_points), args.latent_dim, args.gen_hidden, \n",
    "        embed_time=128, learn_emb=args.learn_emb, num_heads=args.dec_num_heads).to(device)\n",
    "\n",
    "print(f'Encoder: ', args.enc, '\\nDecoder: ', args.dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up optimizer, tensorboard, load model weights (and more?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: 49720 64636\n",
      "Path:  /home2/joshua.wendland/Documents/sepsis/imputation/mTAN/runs/toy_josh/2022.12.02-11.17.15\n"
     ]
    }
   ],
   "source": [
    "params = (list(dec.parameters()) + list(rec.parameters()))\n",
    "optimizer = optim.Adam(params, lr=args.lr)\n",
    "print('parameters:', utils.count_parameters(rec), utils.count_parameters(dec))\n",
    "if args.fname is not None:\n",
    "    checkpoint = torch.load(args.fname)\n",
    "    rec.load_state_dict(checkpoint['rec_state_dict'])\n",
    "    dec.load_state_dict(checkpoint['dec_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    print('loading saved weights', checkpoint['epoch'])\n",
    "    print('Test MSE', utils.evaluate(dim, rec, dec, test_loader, args, 1))\n",
    "    print('Test MSE', utils.evaluate(dim, rec, dec, test_loader, args, 3))\n",
    "    print('Test MSE', utils.evaluate(dim, rec, dec, test_loader, args, 10))\n",
    "    print('Test MSE', utils.evaluate(dim, rec, dec, test_loader, args, 20))\n",
    "    print('Test MSE', utils.evaluate(dim, rec, dec, test_loader, args, 30))\n",
    "    print('Test MSE', utils.evaluate(dim, rec, dec, test_loader, args, 50))\n",
    "\n",
    "\n",
    "# Set up Tensorboard\n",
    "start_time = datetime.now().strftime(\"%Y.%m.%d-%H.%M.%S\")\n",
    "path = '/home2/joshua.wendland/Documents/sepsis/imputation/mTAN/runs/'\n",
    "path += f'{args.dataset}/'\n",
    "path += f'{start_time}'\n",
    "writer = SummaryWriter(log_dir=path)\n",
    "print('Path: ', path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train through epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (0) must match the size of tensor b (3) at non-singleton dimension 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m     subsampled_data, subsampled_tp, subsampled_mask \u001b[39m=\u001b[39m \\\n\u001b[1;32m     26\u001b[0m         observed_data, observed_tp, observed_mask\n\u001b[1;32m     27\u001b[0m \u001b[39m# Forward pass through encoder\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m out \u001b[39m=\u001b[39m rec(torch\u001b[39m.\u001b[39;49mcat((subsampled_data, subsampled_mask), \u001b[39m2\u001b[39;49m), subsampled_tp)\n\u001b[1;32m     29\u001b[0m qz0_mean \u001b[39m=\u001b[39m out[:, :, :args\u001b[39m.\u001b[39mlatent_dim]\n\u001b[1;32m     30\u001b[0m qz0_logvar \u001b[39m=\u001b[39m out[:, :, args\u001b[39m.\u001b[39mlatent_dim:]\n",
      "File \u001b[0;32m~/Documents/sepsis/imputation/mTAN/mTAN/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/sepsis/imputation/mTAN/src/models.py:119\u001b[0m, in \u001b[0;36menc_mtan_rnn.forward\u001b[0;34m(self, x, time_steps)\u001b[0m\n\u001b[1;32m    117\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfixed_time_embedding(time_steps)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    118\u001b[0m     query \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfixed_time_embedding(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquery\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m))\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 119\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49matt(query, key, x, mask)\n\u001b[1;32m    120\u001b[0m out, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgru_rnn(out)\n\u001b[1;32m    121\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhiddens_to_z0(out)\n",
      "File \u001b[0;32m~/Documents/sepsis/imputation/mTAN/mTAN/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/sepsis/imputation/mTAN/src/models.py:65\u001b[0m, in \u001b[0;36mmultiTimeAttention.forward\u001b[0;34m(self, query, key, value, mask, dropout)\u001b[0m\n\u001b[1;32m     62\u001b[0m value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n\u001b[1;32m     63\u001b[0m query, key \u001b[39m=\u001b[39m [l(x)\u001b[39m.\u001b[39mview(x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mh, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_time_k)\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m     64\u001b[0m               \u001b[39mfor\u001b[39;00m l, x \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinears, (query, key))]\n\u001b[0;32m---> 65\u001b[0m x, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(query, key, value, mask, dropout)\n\u001b[1;32m     66\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mcontiguous() \\\n\u001b[1;32m     67\u001b[0m      \u001b[39m.\u001b[39mview(batch, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mh \u001b[39m*\u001b[39m dim)\n\u001b[1;32m     68\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinears[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m](x)\n",
      "File \u001b[0;32m~/Documents/sepsis/imputation/mTAN/src/models.py:49\u001b[0m, in \u001b[0;36mmultiTimeAttention.attention\u001b[0;34m(self, query, key, value, mask, dropout)\u001b[0m\n\u001b[1;32m     47\u001b[0m scores \u001b[39m=\u001b[39m scores\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mrepeat_interleave(dim, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[39mif\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m     scores \u001b[39m=\u001b[39m scores\u001b[39m.\u001b[39;49mmasked_fill(mask\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m-\u001b[39;49m\u001b[39m3\u001b[39;49m) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1e9\u001b[39;49m)\n\u001b[1;32m     50\u001b[0m p_attn \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msoftmax(scores, dim \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[39mif\u001b[39;00m dropout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (0) must match the size of tensor b (3) at non-singleton dimension 4"
     ]
    }
   ],
   "source": [
    "# Run through epochs\n",
    "for itr in range(1, args.niters + 1):\n",
    "    train_loss = 0\n",
    "    train_n = 0\n",
    "    avg_reconst, avg_kl, mse = 0, 0, 0\n",
    "    if args.kl:\n",
    "        wait_until_kl_inc = 10\n",
    "        if itr < wait_until_kl_inc:\n",
    "            kl_coef = 0.\n",
    "        else:\n",
    "            kl_coef = (1 - 0.99 ** (itr - wait_until_kl_inc))\n",
    "    else:\n",
    "        kl_coef = 1\n",
    "\n",
    "    for train_batch in train_loader:\n",
    "        train_batch = train_batch.to(device)\n",
    "        batch_len = train_batch.shape[0]\n",
    "        observed_data = train_batch[:, :, :dim]\n",
    "        observed_mask = train_batch[:, :, dim:2 * dim]\n",
    "        observed_tp = train_batch[:, :, -1]\n",
    "        if args.sample_tp and args.sample_tp < 1:\n",
    "            subsampled_data, subsampled_tp, subsampled_mask = utils.subsample_timepoints(\n",
    "                observed_data.clone(), observed_tp.clone(), observed_mask.clone(), args.sample_tp)\n",
    "        else:\n",
    "            subsampled_data, subsampled_tp, subsampled_mask = \\\n",
    "                observed_data, observed_tp, observed_mask\n",
    "        # Forward pass through encoder\n",
    "        out = rec(torch.cat((subsampled_data, subsampled_mask), 2), subsampled_tp)\n",
    "        qz0_mean = out[:, :, :args.latent_dim]\n",
    "        qz0_logvar = out[:, :, args.latent_dim:]\n",
    "        # Sampling from latent distribution\n",
    "        # epsilon = torch.randn(qz0_mean.size()).to(device)\n",
    "        epsilon = torch.randn(\n",
    "            args.k_iwae, qz0_mean.shape[0], qz0_mean.shape[1], qz0_mean.shape[2]\n",
    "        ).to(device)\n",
    "        z0 = epsilon * torch.exp(.5 * qz0_logvar) + qz0_mean\n",
    "        z0 = z0.view(-1, qz0_mean.shape[1], qz0_mean.shape[2])\n",
    "        # forward pass through decoder\n",
    "        pred_x = dec(\n",
    "            z0,\n",
    "            observed_tp[None, :, :].repeat(args.k_iwae, 1, 1).view(-1, observed_tp.shape[1])\n",
    "        )\n",
    "        # nsample, batch, seqlen, dim\n",
    "        pred_x = pred_x.view(args.k_iwae, batch_len, pred_x.shape[1], pred_x.shape[2])\n",
    "        # compute loss\n",
    "        logpx, analytic_kl = utils.compute_losses(\n",
    "            dim, train_batch, qz0_mean, qz0_logvar, pred_x, args, device)\n",
    "        loss = -(torch.logsumexp(logpx - kl_coef * analytic_kl, dim=0).mean(0) - np.log(args.k_iwae))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * batch_len\n",
    "        train_n += batch_len\n",
    "        avg_reconst += torch.mean(logpx) * batch_len\n",
    "        avg_kl += torch.mean(analytic_kl) * batch_len\n",
    "        mse += utils.mean_squared_error(\n",
    "            observed_data, pred_x.mean(0), observed_mask) * batch_len\n",
    "\n",
    "    print('Iter: {}, avg elbo: {:.4f}, avg reconst: {:.4f}, avg kl: {:.4f}, mse: {:.6f}'\n",
    "        .format(itr, train_loss / train_n, -avg_reconst / train_n, avg_kl / train_n, mse / train_n))\n",
    "    writer.add_scalar('avg elbo', train_loss / train_n, itr)\n",
    "    writer.add_scalar('avg reconst', -avg_reconst / train_n, itr)\n",
    "    writer.add_scalar('avg kl', avg_kl / train_n, itr)\n",
    "    writer.add_scalar('avg mse', mse / train_n, itr)\n",
    "\n",
    "    if itr % 10 == 0:\n",
    "        mse = utils.evaluate(dim, rec, dec, test_loader, args, 1)\n",
    "        writer.add_scalar('Test MSE', mse, itr)\n",
    "        print('Test Mean Squared Error', mse)\n",
    "    if itr % 10 == 0 and args.save:\n",
    "        path_save = path + args.dataset + '_' + args.enc + '_' + args.dec + '_' + str(experiment_id) + '.h5'\n",
    "        torch.save({\n",
    "            'args': args,\n",
    "            'epoch': itr,\n",
    "            'rec_state_dict': rec.state_dict(),\n",
    "            'dec_state_dict': dec.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': -loss,\n",
    "        }, path_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = t.zeros((3,3))\n",
    "b = t.ones((3,3))\n",
    "c = t.zeros(3).unsqueeze(1)\n",
    "dim = a.shape[0]\n",
    "t.concatenate((a,b,c), dim=1)[:, dim:2*dim]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('mTAN': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c0149bcba5d57c6c5fe6ec16c81707307f68ffca57204c4f3e4ca3000c08467"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
